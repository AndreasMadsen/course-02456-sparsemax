\section{Conclusion}

We have shown how to successfully implemented sparsemax in TensorFlow for both the CPU and GPU using C++ and CUDA. In parcular we have shown that the sparsemax and sparsemax loss can be made sutiable for parallel GPU implementation, by applying only minor changes to the algorithms and equations. Our results shows that the sparsemax implementation is slightly but significantly slower than the softmax implementation. But this is expected as it isn't optimiazed as much as the TensorFlow native softmax implementation. We have high hopes for the the computational performance properties of sparsemax because it doesn't use any complex function, such as $\mathrm{exp}(\cdot)$. On the other hand it depends on parallel sorting algorithm, which is particually difficult for GPUs.

Using this sparsemax implementation, we have appiled sparsemax to both multi-class and multi-label classification, as well as to the attention mechanism in a encoder-decoder model. Our results shows that for simple classification using sparsemax performs similarly to using softmax. Only for one dataset, Iris, did we get improved results by using sparsemax. We suspect this is because Iris is a very small dataset, thus sparsemax acts as a bias torewards 0 and 1, which improves the performance. This would be similar to using a prior in Bayesian statistics.

In the encoder-decoder model results showed a huge performance gain by using sparsemax. For a synthetic seq2seq problem the validation accuracy went from 75\% to 98\% by using sparsemax. The attention plots also shows very accurate and sparse attention weights, when using sparsemax. One initial fear was that if $\mathrm{sparsemax}(\cdot)$ produced an ``indicator'' vector for the attention weights, then the gradient would become zero and the model would be untrainable. However this did not turn out to be a problem in practice.